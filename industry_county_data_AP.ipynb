{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7785013-493c-4b8e-8d96-30d8f7caf822",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INDUSTRY BY COUNTY DATA - Alanis Perez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0adde8d-ebb0-41cf-9454-dfd8db03de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a64330b-2c6d-4192-bedc-d5d54a2fea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single CSV file\n",
    "def indent_count(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find the index of the line containing \"Total, All Industries\"\n",
    "    start_index = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"Total, All Industries\" in line:\n",
    "            start_index = i + 1  # Start after this line\n",
    "            break\n",
    "\n",
    "    # If \"Total, All Industries\" was found, process lines from that point onward\n",
    "    if start_index is not None:\n",
    "        data = []\n",
    "        for line in lines[start_index:]:  # Process only from the identified start index\n",
    "            stripped_line = line.strip()\n",
    "            leading_spaces = len(line) - len(stripped_line)\n",
    "            indentation_level = leading_spaces // 2  # Assuming 2 spaces per indentation\n",
    "            \n",
    "            # Append the line and its indentation level to the data list\n",
    "            data.append((stripped_line, indentation_level))\n",
    "\n",
    "        # Create a DataFrame from the data\n",
    "        df = pd.DataFrame(data, columns=['Industry', 'Indentation Level'])\n",
    "\n",
    "        # Filter the DataFrame to include only rows with indentation levels of 3 or greater\n",
    "        df_filtered = df[df['Indentation Level'] >= 3]\n",
    "\n",
    "        # Group industries based on indentation level\n",
    "        df_filtered['Main Category'] = df_filtered.apply(lambda x: x['Industry'] if x['Indentation Level'] == 4 else None, axis=1)\n",
    "        df_filtered['Main Category'].fillna(method='ffill', inplace=True)  # Forward fill to assign main category to subcategories\n",
    "\n",
    "        return df_filtered\n",
    "    else:\n",
    "        print(\"No main categories found.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "81dae18e-f1a5-4d65-8d25-2f9846819ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No main categories found.\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# # Call indent_count function on all counties\n",
    "alpine_path = 'data/OG_county/Alpine_county.csv'\n",
    "# _path = 'data/OG_county/_county.csv'\n",
    "\n",
    "alpine_industries = indent_count(alpine_path)\n",
    "print(alpine_industries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ad0b4d43-4661-452a-89f3-bfa7e036cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single CSV file\n",
    "def industry_combine(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Find the index of the line containing \"Total, All Industries\"\n",
    "    start_index = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"Total, All Industries\" in line:\n",
    "            start_index = i + 1  # Start after this line\n",
    "            break\n",
    "\n",
    "    # If \"Total, All Industries\" was found, process lines from that point onward\n",
    "    if start_index is not None:\n",
    "        data = []\n",
    "        for line in lines[start_index:]:  # Process only from the identified start index\n",
    "            stripped_line = line.strip()\n",
    "            leading_spaces = len(line) - len(stripped_line)\n",
    "            indentation_level = leading_spaces // 2  # Assuming 2 spaces per indentation\n",
    "            \n",
    "            # Append the line and its indentation level to the data list\n",
    "            data.append((stripped_line, indentation_level))\n",
    "\n",
    "        # Create a DataFrame from the data\n",
    "        df = pd.DataFrame(data, columns=['Industry', 'Indentation Level'])\n",
    "\n",
    "        # Filter the DataFrame to include only rows with indentation levels of 3 or greater\n",
    "        df_filtered = df[df['Indentation Level'] >= 3]\n",
    "\n",
    "        # Create a new DataFrame to hold combined categories\n",
    "        combined_data = []\n",
    "        current_main_category = None\n",
    "        current_subcategories = []\n",
    "\n",
    "        for index, row in df_filtered.iterrows():\n",
    "            industry = row['Industry']\n",
    "            indentation_level = row['Indentation Level']\n",
    "\n",
    "            if indentation_level == 3:\n",
    "                # If we were already tracking a main category, save it before starting a new one\n",
    "                if current_main_category is not None:\n",
    "                    combined_data.append((current_main_category, ', '.join(current_subcategories)))\n",
    "\n",
    "                # Start a new main category\n",
    "                current_main_category = industry\n",
    "                current_subcategories = []  # Reset subcategories list\n",
    "\n",
    "            elif indentation_level == 4:\n",
    "                # Add subcategory to the current main category\n",
    "                current_subcategories.append(industry)\n",
    "\n",
    "        # Don't forget to add the last main category and its subcategories\n",
    "        if current_main_category is not None:\n",
    "            combined_data.append((current_main_category, ', '.join(current_subcategories)))\n",
    "\n",
    "        # Create a new DataFrame from the combined data\n",
    "        combined_df = pd.DataFrame(combined_data, columns=['Main Category', 'Subcategories'])\n",
    "\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"No main categories found.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7332b3ec-691c-462a-a84c-e679766bff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "No main categories found.\n",
      "Files with no main categories found:\n",
      "Alpine_county.csv\n",
      "Glenn_county.csv\n",
      "Imperial_county.csv\n",
      "Kings_county.csv\n",
      "Lake_county.csv\n",
      "Mariposa_county.csv\n",
      "Mendocino_county.csv\n",
      "Mono_county.csv\n",
      "Nevada_county.csv\n",
      "Plumas_county.csv\n",
      "SanJoaquin_county.csv\n",
      "Sierra_county.csv\n",
      "Solano_county.csv\n",
      "Sonoma_county.csv\n"
     ]
    }
   ],
   "source": [
    "# Call industry_combine function on all counties\n",
    "directory_path = 'data/OG_county'\n",
    "output_directory = 'data/Industry_combined_data'\n",
    "\n",
    "# List to store names of files with no main categories found\n",
    "no_categories_files = []\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        combined_data = industry_combine(file_path)\n",
    "        \n",
    "        if combined_data is None or combined_data.empty:  # Check if no main categories found\n",
    "            no_categories_files.append(filename)\n",
    "        else:\n",
    "            # Create a new CSV file for each combined result\n",
    "            output_file_path = os.path.join(output_directory, f'combined_{filename}')\n",
    "            combined_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Print the list of files with no main categories found\n",
    "if no_categories_files:\n",
    "    print(\"Files with no main categories found:\")\n",
    "    for file in no_categories_files:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"All files had main categories found.\")\n",
    "\n",
    "# riverside_path = 'data/OG_county/Riverside_county.csv'\n",
    "# Riverside_industries_combined = industry_combine(riverside_path)\n",
    "\n",
    "# # Display the processed DataFrame\n",
    "# print(Riverside_industries_combined)\n",
    "\n",
    "# # Save the combined DataFrame to a CSV file\n",
    "# Riverside_industries_combined.to_csv('data/Industry_combined_data/Riverside_industries_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bafcec03-1b00-4b6f-8dd9-630cb8503766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the combined DataFrame\n",
    "def transform_combined_data(file_path):\n",
    "    # Load the combined data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Split the 'Main Category' column into separate columns\n",
    "    # This assumes the format is \"Industry Name,numerical values\"\n",
    "    categories_split = df['Main Category'].str.split(',', expand=True)\n",
    "\n",
    "    # Create new column names for years 2010 to 2024\n",
    "    year_columns = [f\"{year}_Average\" for year in range(2010, 2025)]\n",
    "\n",
    "    # Prepare the new DataFrame with the required columns\n",
    "    transformed_df = pd.DataFrame(columns=[\"Main Category\"] + year_columns)\n",
    "\n",
    "    # Iterate through each row in the split categories\n",
    "    for index, row in categories_split.iterrows():\n",
    "        # The first value is the Main Category\n",
    "        main_category = row[0]\n",
    "        \n",
    "        # The remaining values are the averages\n",
    "        averages = row[1:].tolist()\n",
    "        \n",
    "        # Fill the remaining values with NaN if there are fewer than 15\n",
    "        while len(averages) < 15:\n",
    "            averages.append(float('nan'))  # Append NaN to fill the gap\n",
    "        \n",
    "        # Create a new row for the transformed DataFrame\n",
    "        transformed_df.loc[index] = [main_category] + averages[:15]  # Only take the first 15 values\n",
    "\n",
    "    # # Save the transformed DataFrame to a new CSV file\n",
    "    # transformed_df.to_csv('Riverside_industries_transformed.csv', index=False)\n",
    "\n",
    "    # return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47541c5a-d259-4d79-95fb-761212a53a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can call the function with the file path\n",
    "file_path = 'Riverside_industries_combined.csv'\n",
    "transformed_data = transform_combined_data(file_path)\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(transformed_data)\n",
    "\n",
    "# Save new csv files\n",
    "Riverside_industries_combined.to_csv('data/Industry_data/Riverside_industries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14693f-2511-4164-999c-e59ba47dbe53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c941b60-f6e4-44ee-9a63-6361a8070d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a20968-2abe-4c0f-a84d-fc6683bfedbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb2f7e-6e28-4a0e-a27e-0cbf0d30c147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0bc394-0c43-41e5-bbd7-dac56aa53c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7d5cf-6a44-43e1-b578-ec5b104af4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f4a78-b8ea-4c5a-9f6b-804772015783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e2287-ebdc-4574-8659-bd933bfe82c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d4af5-8df5-4f70-96eb-10bd8627dd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30264daa-a879-446d-bd66-380c91410c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de9549-7466-4ee6-9686-974b715c0f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6e4cc9c-3893-4382-88ab-200f48047062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold files for all 58 counties\n",
    "dataframes = []\n",
    "\n",
    "# Loop through all CSV files in the directory\n",
    "for county in glob.glob(\"data/Industry_data/*.csv\"):\n",
    "    # Read the CSV file\n",
    "    \n",
    "    county_df = pd.read_csv(county)\n",
    "    \n",
    "    # Extract county name from the filename, assign county ID to be name of county\n",
    "    county_id = county.split(\"/\")[-1].replace(\".csv\", \"\").replace(\"data\\\\\", \"\").replace(\"_county\", \"\")\n",
    "    county_df['County_ID'] = county_id\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(county_df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Export to JSON\n",
    "combined_df.to_json(\"data/industry_county.json\", orient=\"records\")\n",
    "\n",
    "# NEXT !!!!!!\n",
    "# industry_df = pd.read_json('industry_county.json')\n",
    "# industry_df = industry_df.set_index(\"County_ID\")\n",
    "# industry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a8b34a-333b-41ac-90e0-7aceec7fbcf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
